import os
from openai import OpenAI
from dotenv import load_dotenv

# Cargar variables del .env
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=api_key)

def generar_rama_con_ia(historia_base, numero):
    prompt = f"""
ImaginÃ¡ que estÃ¡s escribiendo una historia alternativa. El hecho es: "{historia_base}".

EscribÃ­ una versiÃ³n detallada de lo que habrÃ­a pasado en esta lÃ­nea temporal #{numero}.
DescribÃ­ los eventos histÃ³ricos clave, consecuencias polÃ­ticas, tecnolÃ³gicas y sociales.
No repitas el hecho base, empezÃ¡ directamente con las consecuencias. MantenÃ© un tono narrativo.

LÃ­nea temporal #{numero}:
"""

    respuesta = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Sos un historiador experto en universos alternativos."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.9,
        max_tokens=700
    )

    return respuesta.choices[0].message.content.strip()

def main():
    print("ğŸ•°ï¸  Bienvenido a What If: Historia Alternativa")
    hecho = input("ğŸ” IngresÃ¡ un hecho histÃ³rico alternativo (ej: 'Hitler fue aceptado en la academia de arte'): ")

    print("\nğŸ”® Generando lÃ­neas temporales con IA...\n")

    for i in range(1, 4):
        rama = generar_rama_con_ia(hecho, i)
        print(f"ğŸŒ LÃ­nea temporal #{i}:\n{rama}\n{'-'*60}\n")

if __name__ == "__main__":
    main()

